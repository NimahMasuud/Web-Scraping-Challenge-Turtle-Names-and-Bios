{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dk-fkou7NKT2",
        "outputId": "e32f6d79-f1a2-4b20-f81c-ff2327d6fc5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iframe URL found: /pages/frames/?frame=i\n",
            "Data saved as turtle_data.csv\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import csv\n",
        "from urllib.parse import urljoin\n",
        "\n",
        "# The URL of the website that contains a frame or iframe to be scraped.\n",
        "url = \"https://www.scrapethissite.com/pages/frames/\"\n",
        "\n",
        "# Sending an HTTP GET request to the specified URL.\n",
        "response = requests.get(url)\n",
        "response.raise_for_status()\n",
        "\n",
        "# Parsing the HTML content of the response using BeautifulSoup.\n",
        "soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "# Find the <iframe> element.\n",
        "iframe = soup.find('iframe')\n",
        "\n",
        "# Check if the iframe was found.\n",
        "if iframe:\n",
        "    # Extract the 'src' attribute (the source URL of the iframe).\n",
        "    iframe_src = iframe.get('src')\n",
        "    print(f\"Iframe URL found: {iframe_src}\")\n",
        "\n",
        "    # Construct the full URL for the iframe's source.\n",
        "    iframe_url = urljoin(url, iframe_src)\n",
        "\n",
        "    # Send an HTTP GET request to the iframe's URL to fetch its content.\n",
        "    iframe_response = requests.get(iframe_url)\n",
        "    iframe_response.raise_for_status()\n",
        "\n",
        "    # Parse the HTML content of the iframe using BeautifulSoup.\n",
        "    iframe_soup = BeautifulSoup(iframe_response.text, 'html.parser')\n",
        "\n",
        "    # Find all <h3> elements with the class 'family-name' within the iframe's HTML.\n",
        "    turtles = iframe_soup.find_all('h3', class_='family-name')\n",
        "    turtle_bio = iframe_soup.find_all('a', class_='btn btn-default btn-xs')\n",
        "    print(turtle_bio)\n",
        "\n",
        "\n",
        "    # Open a CSV file for writing.\n",
        "    with open('turtle_data.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
        "        # Create a CSV writer object.\n",
        "        writer = csv.DictWriter(csvfile, fieldnames=['name', 'bio'])\n",
        "\n",
        "        # Write the header to the CSV file.\n",
        "        writer.writeheader()\n",
        "\n",
        "        # Loop through each turtle and write the data to the CSV file.\n",
        "        for turtle in turtles:\n",
        "            writer.writerow({'name': turtle.text.strip()})\n",
        "\n",
        "    print(\"Data saved as turtle_data.csv\")\n",
        "else:\n",
        "    # If no iframe is found, print a message.\n",
        "    print(\"Iframe not found!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jTiodIqwXE7D"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}